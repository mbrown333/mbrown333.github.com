webpackJsonp([0x969091199f8d],{514:function(e,t){e.exports={data:{site:{siteMetadata:{title:"Matthew Brown's JS Blog",author:"Matthew Brown"}},markdownRemark:{id:"/Users/travis/build/mbrown333/mbrown333.github.io/src/pages/20170630-image-upload-app-part1/index.md absPath of file >>> MarkdownRemark",html:'<h1></h1>\n<p>In this four part article we will be building a web application that allows user to upload images and manage those images through the user interface. We will be using NodeJS to build a couple of RESTful APIs, PostgreSQL for a data store, and an Angular 4 front end. </p>\n<p>We’ll also be using Docker to containerize the databases, Node services, and the UI server. Also for file storage we will be using Amazon S3. I’ve tried to simplify this example as much as possible, but there are still quite a few steps to go through to build our application. Here’s an overview of what we’ll be tackling in each part of the article: </p>\n<ul>\n<li><strong>Part 1:</strong> Set up our containers with Docker</li>\n<li><strong>Part 2:</strong> Build a RESTful web service with NodeJS/Express for users and JWT authentication</li>\n<li><strong>Part 3:</strong> Build a RESTful web service with NodeJS/Express for image uploads and store uploads in Amazon S3</li>\n<li><strong>Part 4:</strong> Build the User interface using Angular 4</li>\n</ul>\n<p>The source code can be found on <a href="https://github.com/mbrown333/angular4-node-image-upload-app">github</a>. </p>\n<p> <strong>Prerequisites</strong> Install Docker: <a href="https://www.docker.com/community-edition">https://www.docker.com/community-edition</a> Install latest versions of Node/npm Clone the project directory and checkout the Part1 tag: </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">git clone https://github.com/mbrown333/angular4-node-image-upload-app.git \ncd angular4-node-image-upload-app git checkout tag/Part1</code></pre>\n      </div>\n<h2>Users and Images Databases</h2>\n<p>Docker is a popular development tool used to create portable and lightweight containers for running applications with all of the dependencies involved. I’m assuming you’re familiar with Docker already, but if not check it out here: <a href="https://www.docker.com/">https://www.docker.com/</a>. </p>\n<p>The main advantage to using containers is you can run it on any machine and get the exact same behavior from your application. We’ll start by building out our database containers. We will be using PostgreSQL for our data stores.2 </p>\n<p>PostgreSQL is an open source relational database. We’ll be using an ORM called knex, but more on that later. Docker makes it very easy to get instances of our databases up and running. First, open up a command prompt in the project repository and change into the <code class="language-text">/users-api</code> and create a directory called <code class="language-text">/db</code>. In that directory we’ll create an SQL script to create the users database.\n<em>/users-api/db/create.sql</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">CREATE DATABASE users;</code></pre>\n      </div>\n<p>And then we’ll add the Dockerfile for our user database:\n<em>/users-api/db/Dockerfile</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">FROM postgres \nADD create.sql /docker-entrypoint-initdb.d</code></pre>\n      </div>\n<p>This specifies for Docker to use the postgres image which is already defined. The second lines adds our script for creating the users database within the container when it starts. Adding it to <code class="language-text">/docker-entrypoint-initdb.d</code> ensures that it will get executed when the container boots up. The final piece we need to put in place before starting up our users database connection is the docker-compose.yml file in the project root folder: </p>\n<p><em>/docker-compose.yml</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">version: &#39;2.1&#39; \n\nservices: \n  users-db: \n    container_name: users-db \n    build: ./users-api/db \n    ports: \n      - &#39;5433:5432&#39; \n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=postgres \n    healthcheck: \n      test: exit 0</code></pre>\n      </div>\n<p>We’ll add more to this file as we go, but let’s note a few things here. We give the container the name users-db which we’ll use here in a moment to start the container. </p>\n<p>We’re exposing the 5432 port (default for PostgreSQL) on the container to port 5433 on our host machine. And we’re declaring the PostgreSQL default admin username and password for the container. </p>\n<p>Now let’s get our first container up and running. From a command prompt in the root folder of our project enter: <code class="language-text">docker-compose up --build -d users-db</code>. To see the status of all running containers use the command <code class="language-text">docker-compose ps</code>. </p>\n<p>Some other useful commands: Tail container logs: <code class="language-text">docker-compose logs -f users-db</code>\nOpen up a bash in a container: <code class="language-text">docker-compose run users-db bash</code> (then <code class="language-text">exit</code> to close) </p>\n<p>Our container is now running in the background. Easy enough right? We’ll follow the same steps to kick off our images database. </p>\n<p><em>/images-api/db/create.sql</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">CREATE DATABASE images;</code></pre>\n      </div>\n<p><em>/images-api/db/Dockerfile</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">FROM postgres \nADD create.sql /docker-entrypoint-initdb.d</code></pre>\n      </div>\n<p><em>/docker-compose.yml</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">version: &#39;2.1&#39; \n\nservices: \n  users-db: \n    container_name: users-db \n    build: ./users-api/db \n    ports: \n      - &#39;5433:5432&#39; \n    environment: \n      - POSTGRES_USER=postgres \n      - POSTGRES_PASSWORD=postgres \n    healthcheck: \n      test: exit 0 \n  images-db: \n    container_name: images-db \n    build: ./images-api/db \n    ports: \n      - &#39;5434:5432&#39; \n    environment: \n      - POSTGRES_USER=postgres \n      - POSTGRES_PASSWORD=postgres \n    healthcheck: \n      test: exit 0</code></pre>\n      </div>\n<p>Very similar to before. Only real change is we give our image database container the name images-db and connect it to the 5434 host port. And now we’re ready to kick off this container as well: <code class="language-text">docker-compose up --build -d images-db</code>.</p>\n<p>And then there were two. If we run the <code class="language-text">docker-compose ps</code> command again we’ll see the following if all went well: </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">Name Command State Ports \n-------------------------------------------------------------------------- \nimages-db docker-entrypoint.sh postgres Up 0.0.0.0:5434-&gt;5432/tcp \nusers-db docker-entrypoint.sh postgres Up 0.0.0.0:5433-&gt;5432/tcp </code></pre>\n      </div>\n<h2>Users and Images NodeJs/Express Services</h2>\n<p>Now that we have our database ready to go, we’ll move on to our two services. We’ll start with our users service first, but as with the database containers both services will look similar. </p>\n<p><em>/users-api/Dockerfile</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text">FROM node:latest \n\n# set working directory \nRUN mkdir /usr/src/app \nWORKDIR /usr/src/app \n\n# add `/usr/src/node_modules/.bin` to $PATH \nENV PATH /usr/src/app/node_modules/.bin:$PATH \n\n# install and cache app dependencies \nADD package.json /usr/src/app/package.json \nRUN npm install \n\n# start app \nCMD [&quot;npm&quot;, &quot;start&quot;]</code></pre>\n      </div>\n<p>There’s a little more to this Dockerfile than what we saw with the databases. We’re using the node image from Docker, setting up a directory for our application on the container machine, adding the node_modules folder to the PATH, and then installing all of our npm dependencies. After all this is complete, the container will run npm start which will kick off the node server. If you look in the package.json we have specified <code class="language-text">nodemon server.js</code> which will run the server and automatically restart it if it errors out for any reason. </p>\n<p>Now we’ll add our users-api to the docker compose yaml file: </p>\n<p><em>/docker-compose.yml</em> </p>\n<div class="gatsby-highlight">\n      <pre class="language-text"><code class="language-text"> .. \n  users-api: \n    container_name: users-api \n    build: ./users-api/ \n    volumes: \n      - &#39;./users-api:/usr/src/app&#39; \n      - &#39;./users-api/package.json:/usr/src/package.json&#39; \n      - /usr/src/app/node_modules \n    ports: \n      - &#39;3000:3000&#39; \n    environment: \n      - DATABASE_URL=postgres://postgres:postgres@users-db:5432/users \n      - NODE_ENV=${NODE_ENV} \\- TOKEN_SECRET=ICzX8uISDW9Bv2ZcsPUbeZx8tpVa6ajS \n    depends_on: \n      users-db: condition: service_healthy \n    links: \n      - users-db</code></pre>\n      </div>',frontmatter:{title:"Building an Image Upload App with Angular 4, NodeJS, PostgreSQL, and Amazon S3 - Part 1",date:"June 30, 2017"}}},pathContext:{slug:"/20170630-image-upload-app-part1/",previous:null,next:{fields:{slug:"/20170630-image-upload-app-part2/"},frontmatter:{title:"Building an Image Upload App with Angular 4, NodeJS, PostgreSQL, and Amazon S3 – Part 2"}}}}}});
//# sourceMappingURL=path---20170630-image-upload-app-part-1-9f28bce27eef33cae2b8.js.map